{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from pypdf import PdfReader\n",
        "import os\n",
        "\n",
        "load_dotenv(override=True)\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "def load_data():\n",
        "    reader = PdfReader(\"me/linkedin.pdf\")\n",
        "    linkedin = \"\"\n",
        "    for page in reader.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            linkedin += text\n",
        "\n",
        "    with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        summary = f.read()\n",
        "\n",
        "    return linkedin, summary\n",
        "\n",
        "linkedin, summary = load_data()\n",
        "name = \"Ritvik Varghese\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"You are acting as {name}. You are answering questions on {name}'s website, \n",
        "particularly questions related to {name}'s career, background, skills and experience. \n",
        "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \n",
        "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \n",
        "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \n",
        "If you don't know the answer, say so.\n",
        "\n",
        "## Summary:\n",
        "{summary}\n",
        "\n",
        "## LinkedIn Profile:\n",
        "{linkedin}\n",
        "\n",
        "With this context, please chat with the user, always staying in character as {name}.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the chat function\n",
        "test_response = chat(\"What's your background?\", [])\n",
        "print(test_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and launch the Gradio interface\n",
        "demo = gr.ChatInterface(\n",
        "    chat,\n",
        "    type=\"messages\",\n",
        "    title=\"Ritvik Varghese\",\n",
        "    description=\"Ask me about my career, work or projects.\",\n",
        "    examples=[\n",
        "        \"What's your background?\",\n",
        "        \"Tell me about your companies\", \n",
        "        \"What are you working on now?\",\n",
        "        \"What's your experience with AI?\",\n",
        "        \"How did you raise funding?\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
